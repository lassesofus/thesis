\subsection{Zero-Shot Single-Axis Reaching Correlation}
\label{sec:zero_shot_axis_correlation}

To evaluate the structure of the pretrained V-JEPA 2 encoder's latent space, we analyze the correlation between physical distances and latent distances in a zero-shot setting. This experiment tests whether the encoder, without any robot-specific fine-tuning, has learned representations that meaningfully correspond to spatial relationships.

\subsubsection{Data Generation}

We generated 50 reaching trajectories along each of the three Cartesian axes (X, Y, and Z) using the DROID simulator. Each trajectory has a fixed reach distance of 0.2\,m and a horizon of 4.5 seconds. The trajectories were generated using \texttt{generate\_axis\_trajectories.sh}, which calls the trajectory generation script with axis-specific parameters:

\begin{itemize}
    \item \textbf{X-axis}: 50 trajectories moving along the X direction
    \item \textbf{Y-axis}: 50 trajectories moving along the Y direction
    \item \textbf{Z-axis}: 50 trajectories moving along the Z direction
\end{itemize}

Each axis uses a different random seed to ensure trajectory diversity while maintaining reproducibility.

\subsubsection{Analysis Method}

For each trajectory, we compute the correlation between the Euclidean distance to the goal position and the L1 distance in latent space. The analysis proceeds as follows:

\begin{enumerate}
    \item Load the pretrained V-JEPA 2 encoder (ViT-Giant architecture) without any fine-tuning
    \item For each frame in a trajectory, encode both the current frame and the goal frame together as a 2-frame video
    \item Compute the Euclidean distance from the current end-effector position to the goal position
    \item Compute the mean L1 distance between the current and goal frame representations in latent space
    \item Calculate the Pearson correlation coefficient across all frames from all trajectories for each axis
\end{enumerate}

\subsubsection{Results}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{experiments/01_zero_shot_single_axis_reaching/zero_shot_axis_correlation.png}
    \caption{Correlation between Euclidean distance to goal and L1 distance in latent space for the pretrained V-JEPA 2 encoder across three movement axes. Each subplot shows data from 50 trajectories (1320 points total). The dashed red line indicates the linear trend. High Pearson correlations ($r > 0.9$) across all axes demonstrate that the pretrained encoder's latent space captures meaningful spatial structure without robot-specific fine-tuning.}
    \label{fig:zero_shot_axis_correlation}
\end{figure}

Figure~\ref{fig:zero_shot_axis_correlation} shows the correlation results for each axis. The pretrained encoder achieves high correlations across all three axes:

\begin{itemize}
    \item \textbf{X-axis}: $r = 0.91$
    \item \textbf{Y-axis}: $r = 0.93$
    \item \textbf{Z-axis}: $r = 0.92$
\end{itemize}

These strong correlations indicate that the V-JEPA 2 encoder has learned representations where distances in latent space correspond to distances in physical space, even without any task-specific training. This suggests that the self-supervised pretraining objective encourages the model to capture spatial relationships that are useful for robotic manipulation tasks.
